# Data_Engineering_Twitter-data

This Project intended to describe a prototype of a data pipeline using Apache Kafka and addresses the three main layers of data pipeline that are data ingestion, data storage, and data processing/visualization. We are using Apache Kafka as a platform for streaming of data across distributed systems. Furthermore, the steps involved in creating the layers are explained in detail along with the analysis of the data.
